import fs from "fs";
import * as gremlin from "gremlin";
import {process as p} from "gremlin";
import {createGraphDB, graphClient, redisClient, wikipediaCrawler} from "./server_module";
import {CrawlerRecord} from "./crawler";
import {insertCrawlerRecord} from "./graph";
// RxJS v6+
import {from, of} from "rxjs";
import {catchError, concatMap, tap} from "rxjs/operators";
import {Server} from "./server";
import {URL} from "url";
import {GremlinConnection} from "./graph/gremlin_connection";
import {Preconditions} from "../../../../common/src/main/ts/preconditions";
import {sys} from "typescript";
import GraphTraversal = p.GraphTraversal;
import {createGraphDBConnection} from "./graph/gremlin";

const addV = gremlin.process.statics.addV;
const addE = gremlin.process.statics.addE;
const fold = gremlin.process.statics.fold;
const unfold = gremlin.process.statics.unfold;
const inV = gremlin.process.statics.inV;
const outV = gremlin.process.statics.outV;
const inE = gremlin.process.statics.inE;
const outE = gremlin.process.statics.outE;

new Server().start();
try {
  start();
} catch (err) {
  console.error(err);
  sys.exit();
}

// async function start() {
//   const g = await createGraphDB();
//   await g.V().drop().iterate();
//   await g
//     .addV("url")
//       .property("hreff", "en.wikipedia.com/wiki/Main_page")
//       .property("namee", "Main_page")
//     .iterate();
//
//   setTimeout(() => {
//     g.V().limit(10).valueMap().toList().
//     then(data => {
//       console.log(data);
//     }).catch(error => {
//       console.log('ERROR', error);
//     });
//   }, 1000);
//
//   const gremlin: GremlinConnection = await graphClient();
//   const addVertex = (grr: GraphTraversal) => grr
//     .V()
//     .addV("url")
//     .property("hreffff", "en.wikipedia.com/wiki/Main_page")
//     .property("nameeee", "Main_page");
//
//   const resp = await gremlin.iterate(addVertex);
//   console.log(resp);
//   setTimeout(() => {
//     g.V().limit(10).valueMap().toList().
//     then(data => {
//       console.log("Part 1");
//       console.log(data);
//     }).catch(error => {
//       console.log('ERROR', error);
//     });
//   }, 1000);
//   setTimeout(() => {
//     gremlin.toList((ggrr: any) => ggrr.V().limit(10).valueMap()).
//     then(data => {
//       console.log("Part 2");
//       console.log(data);
//     }).catch(error => {
//       console.log('ERROR', error);
//     });
//   }, 1000);
// }

async function start() {
  try {
    // const seedUrls = getSeed();
    // console.log(`Seed urls: \n${seedUrls}`);
    // const redisConnection = redisClient("debugger");
    // await redisConnection.del("history");
    // await redisConnection.del("queue");

///////////////////////////
    // console.log("Drop all vertices");
    // await gremlin.iterate((g: GraphTraversal) => g.V().drop());
    // await gremlin.toList(vertexCountQuery).then(console.log);
    //
    // console.log("Schedule vertex count");
    // setInterval(() => gremlin.toList(vertexCountQuery).then(console.log), 2000);
    //
    // console.log("Add wadejensen");
    // const addVertex = (g: GraphTraversal) => g
    //   .V()
    //   .addV("url")
    //     .properties("href", "wadejensen")
    //     .property("nameeee", "Main_page");
    //
    // const resp0 = await gremlin.toList(addVertex);
    // console.log(resp0);
    //
    // console.log("Add jensenwade");
    // const addVertexx = (g: GraphTraversal) => g
    //   .V()
    //   .addV("url")
    //   .properties("href", "jensenwade")
    //   .property("nameeee", "hello world");
    //
    // const resp1 = await gremlin.iterate(addVertexx);
    // console.log(resp1);
    //
    // const getVertices = (g: GraphTraversal) => g
    //   .V()
    //   .limit(10)
    //   .valueMap();
    //
    // console.log("Report results");
    // const resp2 = await gremlin.toList(getVertices);
    // console.log(resp2);

    const gremlin: GremlinConnection = await graphClient();
    const vertexCountQuery = (g: GraphTraversal) => g.V().count();
    await gremlin.iterate((g: GraphTraversal) => g.V().drop());

    console.log(await gremlin.toList(vertexCountQuery));
    console.log("Schedule vertex count");
    setInterval(() => gremlin.toList(vertexCountQuery).then(console.log), 2000);

    const g = await createGraphDB();
    //await g.V().drop().iterate();
    await g
      .addV("url")
      .property("hreff", "en.wikipedia.com/wiki/Main_page")
      .property("namee", "Main_page")
      .iterate();

    setTimeout(() => {
      g.V().limit(10).valueMap().toList().
      then(data => {
        console.log(data);
      }).catch(error => {
        console.log('ERROR', error);
      });
    }, 1000);

    //const gremlin: GremlinConnection = await graphClient();
    const addVertex = (grr: GraphTraversal) => grr
      .V() //unnecessary
      .addV("url")
      .property("hreffff", "en.wikipedia.com/wiki/Main_page")
      .property("nameeee", "Main_page");

    const resp = await gremlin.iterate(addVertex);
    console.log(resp);
    setTimeout(() => {
      g.V().limit(10).valueMap().toList().
      then(data => {
        console.log("Part 1");
        console.log(data);
      }).catch(error => {
        console.log('ERROR', error);
      });
    }, 1000);
    setTimeout(() => {
      gremlin.toList((ggrr: any) => ggrr.V().limit(10).valueMap()).
      then(data => {
        console.log("Part 2");
        console.log(data);
      }).catch(error => {
        console.log('ERROR', error);
      });
    }, 1000);

    console.log("Compare vertex counts");
    console.log(await g.V().count().toList());
    console.log(await gremlin.toList(vertexCountQuery));

    //await resetGraphDb(gremlin, 0);
    const crawler = await wikipediaCrawler().start();

    // log crawler results
    crawler.results.subscribe((record: CrawlerRecord) => {
      console.log(`${record.url}: deg ${record.degree}, found ${record.childUrls.length} links.`)
    });

    // log crawler errors
    crawler.errors.subscribe((err) => console.log(`Crawler error: ${err}`));

    // flush crawler results to Graph DB
    crawler.results.pipe(
        tap((record: CrawlerRecord) => console.log(record.childUrls.length)),
        concatMap((record: CrawlerRecord) => from(insertCrawlerRecord(gremlin, record))),
        catchError((err) => {
          console.error(`Failed to write to Graph DB due to ${err}`);
          return of();
        }),
        tap((x) => console.log(Math.random())),
      )
      .subscribe(() => console.log("Flushed"));

    //seedUrls.forEach(url => crawler.addSeed(new URL(url)));
  } catch (err) {
    console.error(`Unexpected error encountered: ${err}`);
  }
}

function getSeed(): string[] {
  const seedFilePath = process.env["SEED_FILE"]!;
  console.log(seedFilePath);
  Preconditions.checkState(!!seedFilePath);
  const seedFile = fs.readFileSync(seedFilePath, "utf8");
  return seedFile
    .split("\n")
    .filter(line => line.length !== 0)
    .map(line => line.trim());
}

async function resetGraphDb(gremlin: GremlinConnection, i: number): Promise<void> {
  try {
    if (i > 10) {
      console.error("Failed to clear graph db state");
      sys.exit(1);
      return
    }
    console.log("Dropping vertices and edges...");
    await gremlin.iterate((g) => g.V().drop());
  } catch (err) {
    console.error(err);
    await resetGraphDb(gremlin, i + 1);
  }
}
